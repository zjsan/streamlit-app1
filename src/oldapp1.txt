import streamlit as st
from hugchat import hugchat
from hugchat.login import Login

# App title
st.set_page_config(page_title="ü§óüí¨ Cognicraft")

# Hugging Face Credentials
with st.sidebar:
    st.title('COGNICRAFT')


    hf_email = 'zjsantos25@gmail.com'
    hf_pass = 'Th3ege@rprggrmmr1231231'
    #hf_email = st.text_input('Enter E-mail:', type='password')
   # hf_pass = st.text_input('Enter password:', type='password')
   # if not (hf_email and hf_pass):
      #  st.warning('Please enter your credentials!', icon='‚ö†Ô∏è')
    #else:
     #   st.success('Proceed to entering your prompt message!', icon='üëâ')

    #question type
    question_type = st.selectbox(
    "Question Type",
    ("Multiple Choice", "True or False", "Fill in the blanks"),
    index=None,
    placeholder="Select question type...",
    )
        
    if question_type == 'Multiple Choice':
        st.write('Right you Multiple choice')
    elif question_type == 'True or False':
        st.write('True or False')
    elif question_type == 'Fill in the blanks':
        st.write('Fill in the blanks')
    
    #question_number
    question_number = st.text_input('Number of Items')
    
    #taxomy level
    taxonomy_level = st.selectbox(
    "Taxonomy Level",
    ("Remember", "Understand", "Apply", "Analyze", "Evaluate", "Create"),
    index=None,
    placeholder="Select taxonomy level...",
    )

    #difficulty level
    difficulty = st.selectbox(
    "Taxonomy Level",
    ("Easy", "Medium", "Hard"),
    index=None,
    placeholder="Select difficulty level...",
    )

# Store LLM generated responses
if "messages" not in st.session_state.keys():
    st.session_state.messages = [{"role": "assistant", "content": "How may I help you?"}]

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])


def get_input(prepend_text="Can you generate sample 5 questions about: "):
  # Get user input using Streamlit text input
  
  user_input = st.text_input("Enter the:")
  st.write(prepend_text)
  print(prepend_text)

  return prepend_text+user_input

# Function for generating LLM response
def generate_response(prompt_input, email, passwd):
    # Hugging Face Login
    sign = Login(email, passwd)
    cookies = sign.login()
    
    # Create ChatBot                        
    chatbot = hugchat.ChatBot(cookies=cookies.get_dict())
    return chatbot.chat(prompt_input)

# User-provided prompt
if prompt := st.chat_input(disabled=not (hf_email and hf_pass)):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.write(prompt)


# Generate a new response if last message is not from assistant
if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = generate_response(prompt, hf_email, hf_pass) 
            st.write(response) 
    message = {"role": "assistant", "content": response}
    st.session_state.messages.append(message)